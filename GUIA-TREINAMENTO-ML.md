# ğŸ¤– Guia de Treinamento e Registro dos Modelos ML

## ğŸ“‹ Ãndice
1. [PrÃ©-requisitos](#prÃ©-requisitos)
2. [VisÃ£o Geral dos Modelos](#visÃ£o-geral-dos-modelos)
3. [Comando RÃ¡pido (Tudo de uma vez)](#comando-rÃ¡pido)
4. [Comandos Individuais](#comandos-individuais)
5. [VerificaÃ§Ã£o e Testes](#verificaÃ§Ã£o-e-testes)
6. [Troubleshooting](#troubleshooting)

---

## ğŸ¯ PrÃ©-requisitos

### 1. Verificar ambiente
```bash
# Verificar se estÃ¡ no diretÃ³rio correto
pwd  # Deve estar em: /home/rsambing/Projects/Wenda/backend-ml

# Verificar se .env existe
cat .env | grep DATABASE_URL
```

### 2. Verificar tabelas do banco
```bash
# Verificar se tabelas ML existem
python3 scripts/check-ml-tables.py

# Contar registros
python3 scripts/count_records.py

# Ver estatÃ­sticas
python3 scripts/view_database_stats.py
```

### 3. Verificar dados necessÃ¡rios

Para treinar os modelos, vocÃª precisa ter:
- âœ… **Destinations** (mÃ­nimo 10-20 destinos) â†’ para recomendaÃ§Ãµes
- âœ… **Tourism Statistics** (dados histÃ³ricos) â†’ para previsÃ£o e clustering
- âš ï¸ Se nÃ£o tiver dados, use: `python3 scripts/populate_database.py`

---

## ğŸ¯ VisÃ£o Geral dos Modelos

### 1. ğŸ¯ Modelo de RecomendaÃ§Ãµes (Content-Based)
- **Script**: `train_recommender.py`
- **Entrada**: Tabela `destinations`
- **Algoritmo**: TF-IDF + Cosine Similarity
- **SaÃ­da**: 
  - `recommender_similarity_matrix.npy`
  - `recommender_features.npy`
  - `recommender_tfidf.joblib`
  - `recommender_scaler.joblib`
  - `recommender_metadata.json`

### 2. ğŸ‘¥ Modelo de Clustering (Perfis de Viajantes)
- **Script**: `train_clustering.py`
- **Entrada**: Tabela `tourism_statistics`
- **Algoritmo**: K-Means Clustering
- **SaÃ­da**:
  - `clustering_model.joblib`
  - `clustering_scaler.joblib`
  - `clustering_metadata.json`

### 3. ğŸ“ˆ Modelo de PrevisÃ£o (Forecast)
- **Script**: `train_forecast_baseline.py`
- **Entrada**: Tabela `tourism_statistics`
- **Algoritmo**: Random Forest Regressor (por provÃ­ncia)
- **SaÃ­da**:
  - `forecast_Luanda.joblib`
  - `forecast_Benguela.joblib`
  - ... (um por provÃ­ncia)
  - `training_summary.json`

---

## ğŸš€ Comando RÃ¡pido

### OpÃ§Ã£o 1: Script Automatizado (RECOMENDADO)

```bash
# Dar permissÃ£o de execuÃ§Ã£o
chmod +x scripts/train_and_register_all.sh

# Executar tudo de uma vez
bash scripts/train_and_register_all.sh
```

Este script irÃ¡:
1. âœ… Verificar dados no banco
2. âœ… Treinar os 3 modelos
3. âœ… Registrar no banco de dados
4. âœ… Testar endpoints

---

## ğŸ“ Comandos Individuais

### Etapa 1: Treinar Cada Modelo

#### 1.1 Modelo de RecomendaÃ§Ãµes
```bash
python3 scripts/train_recommender.py
```

**SaÃ­da esperada:**
```
ğŸš€ Training Content-Based Recommendation Model
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ“Š Fetching destinations from database...
âœ… Loaded 35 destinations

ğŸ”§ Creating content features...
   â€¢ Text features (TF-IDF): 500 dimensions
   â€¢ Category features: 4 categories
   â€¢ Province features: 13 provinces
   â€¢ Rating features: normalized

âœ… Combined features: 35 destinations Ã— 518 features

ğŸ§® Computing similarity matrix...
âœ… Similarity matrix computed: (35, 35)

ğŸ’¾ Saving model artifacts...
âœ… Model saved to models/

ğŸ‰ Training complete!
```

#### 1.2 Modelo de Clustering
```bash
python3 scripts/train_clustering.py
```

**SaÃ­da esperada:**
```
ğŸš€ Training Tourist Segmentation Model (Clustering)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ“Š Fetching tourism statistics...
âœ… Loaded 120 records

ğŸ”§ Feature engineering...
âœ… Created features: (120, 8)

ğŸ§® Training K-Means clustering...
âœ… Identified 3 tourist segments

ğŸ’¾ Saving model...
âœ… Model saved!
```

#### 1.3 Modelo de PrevisÃ£o
```bash
python3 scripts/train_forecast_baseline.py
```

**SaÃ­da esperada:**
```
ğŸš€ Training Tourism Forecast Models
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ“Š Loading data...
âœ… Loaded 120 records from 13 provinces

ğŸ¯ Training models by province...
   âœ“ Luanda: RÂ²=0.85, MAE=125.3
   âœ“ Benguela: RÂ²=0.82, MAE=98.7
   ...

ğŸ’¾ Saving models...
âœ… 13 models saved!
```

---

### Etapa 2: Registrar Modelos no Banco

```bash
python3 scripts/register_models.py
```

**SaÃ­da esperada:**
```
ğŸš€ Registering Trained Models in Database
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ“Š Connecting to database...
âœ… Connected!

ğŸ“ Registering models...
   âœ… Registered: forecast_Luanda (v1.0.0)
   âœ… Registered: forecast_Benguela (v1.0.0)
   ...
   âœ… Registered: clustering_kmeans (v1.0.0)
   âœ… Registered: recommender_content (v1.0.0)

ğŸ’¾ Total registered: 15 models

ğŸ‰ All models registered successfully!
```

**O que este script faz:**
- LÃª os arquivos de metadata dos modelos
- Insere registros na tabela `ml_models_registry`
- Armazena mÃ©tricas, versÃ£o, algoritmo, data de treinamento

---

## âœ… VerificaÃ§Ã£o e Testes

### 1. Verificar arquivos criados
```bash
# Listar modelos salvos
ls -lh models/

# Ver conteÃºdo dos metadados
cat models/recommender_metadata.json | jq '.'
cat models/clustering_metadata.json | jq '.'
cat models/training_summary.json | jq '.'
```

### 2. Verificar registros no banco
```bash
# Script Python
python3 -c "
import asyncio
import asyncpg
import os
from dotenv import load_dotenv

async def check():
    load_dotenv()
    conn = await asyncpg.connect(os.getenv('DATABASE_URL'))
    
    models = await conn.fetch('SELECT * FROM ml_models_registry ORDER BY last_updated DESC')
    
    print(f'\nğŸ“Š Modelos registrados: {len(models)}\n')
    for m in models:
        print(f'  â€¢ {m[\"model_name\"]} v{m[\"version\"]} - {m[\"status\"]}')
    
    await conn.close()

asyncio.run(check())
"
```

### 3. Testar via API

#### Iniciar servidor
```bash
uvicorn app.main:app --reload
```

#### Testar endpoints (em outro terminal)
```bash
# Listar modelos disponÃ­veis
curl http://localhost:8000/api/ml/models | jq '.'

# Testar recomendaÃ§Ãµes
curl -X POST http://localhost:8000/api/ml/recommend-by-preferences \
  -H "Content-Type: application/json" \
  -d '{
    "preferences": {
      "categories": ["natural"],
      "provinces": ["Luanda"]
    },
    "limit": 5
  }' | jq '.'

# Testar previsÃ£o
curl -X POST http://localhost:8000/api/ml/forecast \
  -H "Content-Type: application/json" \
  -d '{
    "province": "Luanda",
    "month": 12,
    "year": 2025
  }' | jq '.'

# Testar segmentaÃ§Ã£o
curl -X POST http://localhost:8000/api/ml/segment-tourist \
  -H "Content-Type: application/json" \
  -d '{
    "user_behavior": {
      "avg_budget": 5000,
      "preferred_season": "summer",
      "travel_frequency": 3
    }
  }' | jq '.'
```

#### Ou usar o script de teste
```bash
bash scripts/test_trained_models.sh
```

---

## ğŸ”§ Troubleshooting

### âŒ Erro: "No data found in tourism_statistics"

**Problema**: Tabela vazia  
**SoluÃ§Ã£o**:
```bash
# Popular banco com dados de exemplo
python3 scripts/populate_database.py
```

---

### âŒ Erro: "Table 'destinations' does not exist"

**Problema**: Tabelas ML nÃ£o existem  
**SoluÃ§Ã£o**:
```bash
# Verificar tabelas
python3 scripts/check-ml-tables.py

# Se faltarem tabelas, adicione no backend CRUD usando o schema Prisma
# Ver: COPIAR-COLAR-PRISMA.md
```

---

### âŒ Erro: "Module 'sklearn' not found"

**Problema**: DependÃªncias nÃ£o instaladas  
**SoluÃ§Ã£o**:
```bash
# Instalar dependÃªncias
pip install -r requirements.txt

# Ou instalar manualmente
pip install scikit-learn pandas numpy joblib
```

---

### âŒ Erro: "asyncpg.exceptions.InvalidPasswordError"

**Problema**: DATABASE_URL incorreta  
**SoluÃ§Ã£o**:
```bash
# Verificar .env
cat .env | grep DATABASE_URL

# Testar conexÃ£o
python3 scripts/check-tables.py
```

---

### âš ï¸ Aviso: "Low number of destinations (< 10)"

**Problema**: Poucos dados para treinar  
**SoluÃ§Ã£o**:
```bash
# Adicionar mais destinos
python3 scripts/populate_database.py
```

---

### âŒ Erro ao registrar: "duplicate key value violates unique constraint"

**Problema**: Modelo jÃ¡ estÃ¡ registrado  
**SoluÃ§Ã£o**:
```bash
# Deletar registros antigos primeiro
python3 -c "
import asyncio, asyncpg, os
from dotenv import load_dotenv

async def clean():
    load_dotenv()
    conn = await asyncpg.connect(os.getenv('DATABASE_URL'))
    await conn.execute('DELETE FROM ml_models_registry')
    print('âœ… Registros deletados')
    await conn.close()

asyncio.run(clean())
"

# Depois registrar novamente
python3 scripts/register_models.py
```

---

## ğŸ“Š Estrutura de Arquivos apÃ³s Treinamento

```
backend-ml/
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ recommender_similarity_matrix.npy
â”‚   â”œâ”€â”€ recommender_features.npy
â”‚   â”œâ”€â”€ recommender_tfidf.joblib
â”‚   â”œâ”€â”€ recommender_scaler.joblib
â”‚   â”œâ”€â”€ recommender_metadata.json
â”‚   â”œâ”€â”€ clustering_model.joblib
â”‚   â”œâ”€â”€ clustering_scaler.joblib
â”‚   â”œâ”€â”€ clustering_metadata.json
â”‚   â”œâ”€â”€ forecast_Luanda.joblib
â”‚   â”œâ”€â”€ forecast_Benguela.joblib
â”‚   â”œâ”€â”€ forecast_Namibe.joblib
â”‚   â””â”€â”€ training_summary.json
â””â”€â”€ ...
```

---

## ğŸ¯ Resumo dos Comandos

```bash
# OPÃ‡ÃƒO 1: Tudo de uma vez (RECOMENDADO)
bash scripts/train_and_register_all.sh

# OPÃ‡ÃƒO 2: Passo a passo
python3 scripts/train_recommender.py
python3 scripts/train_clustering.py
python3 scripts/train_forecast_baseline.py
python3 scripts/register_models.py

# Testar
uvicorn app.main:app --reload
bash scripts/test_trained_models.sh
```

---

## ğŸ“š DocumentaÃ§Ã£o Adicional

- **Arquitetura ML**: Ver `docs/ml-architecture.md`
- **API Endpoints**: http://localhost:8000/docs
- **Schema do Banco**: `docs/db.txt`
- **AdaptaÃ§Ãµes**: `ADAPTACOES-FEITAS.md`
