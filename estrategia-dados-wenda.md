# üìä Estrat√©gia de Coleta e Gest√£o de Dados - Projeto Wenda

## üéØ Introdu√ß√£o

O projeto **Wenda** √© uma plataforma inteligente de turismo para Angola que utiliza Machine Learning para fornecer recomenda√ß√µes personalizadas e an√°lises preditivas do setor tur√≠stico. A qualidade e diversidade dos dados s√£o fundamentais para o sucesso do modelo de ML, garantindo que as previs√µes e recomenda√ß√µes sejam precisas e relevantes.

Este documento apresenta a estrat√©gia completa de coleta, processamento e armazenamento de dados, abrangendo m√∫ltiplas fontes que incluem:
- **Estat√≠sticas oficiais de turismo**
- **Dados clim√°ticos e meteorol√≥gicos**
- **Informa√ß√µes geogr√°ficas e pontos de interesse**
- **Dados de transporte e conectividade**
- **Avalia√ß√µes e feedback de utilizadores**

---

## üóÇÔ∏è Fontes de Dados e Estrat√©gia de Coleta

### üèõÔ∏è 1. INE Angola - Instituto Nacional de Estat√≠stica

**üîó Link:** [https://www.ine.gov.ao](https://www.ine.gov.ao)

**üìã Descri√ß√£o:**
O INE √© a fonte oficial de estat√≠sticas nacionais de Angola, publicando relat√≥rios detalhados sobre o setor tur√≠stico, incluindo:
- N√∫mero de turistas nacionais e internacionais
- Estat√≠sticas de hospedagem por prov√≠ncia
- Receitas do setor tur√≠stico
- Dados de transporte tur√≠stico
- Indicadores econ√≥micos do turismo

**‚öôÔ∏è M√©todo de Acesso:**
- **T√©cnica:** Web scraping controlado usando `BeautifulSoup` e `Selenium` (Python)
- **Alternativa:** Download manual de relat√≥rios em PDF/Excel quando necess√°rio
- **Frequ√™ncia:** Mensal (novos relat√≥rios) e trimestral (dados consolidados)

**üìÑ Formato dos Dados:**
- PDF (relat√≥rios oficiais)
- XLSX (tabelas estat√≠sticas)
- HTML (dados web)

**üóÑÔ∏è Plano de Armazenamento:**
```
PostgreSQL:
‚îú‚îÄ‚îÄ tabela: ine_tourism_stats
‚îÇ   ‚îú‚îÄ‚îÄ ano (INT)
‚îÇ   ‚îú‚îÄ‚îÄ provincia (VARCHAR)
‚îÇ   ‚îú‚îÄ‚îÄ tipo_turista (ENUM: nacional, internacional)
‚îÇ   ‚îú‚îÄ‚îÄ numero_visitantes (INT)
‚îÇ   ‚îú‚îÄ‚îÄ receita_usd (DECIMAL)
‚îÇ   ‚îî‚îÄ‚îÄ data_atualizacao (TIMESTAMP)
‚îî‚îÄ‚îÄ Google Cloud Storage: /raw/ine/
```

**üéØ Uso no Modelo:**
- Alimentar modelos de previs√£o de demanda tur√≠stica
- An√°lise de sazonalidade por regi√£o
- Dashboards estat√≠sticos no painel administrativo
- Correla√ß√£o entre eventos econ√≥micos e fluxo tur√≠stico

---

### üå¶Ô∏è 2. OpenWeatherMap - Dados Clim√°ticos

**üîó Link:** [https://openweathermap.org/api](https://openweathermap.org/api)

**üìã Descri√ß√£o:**
API completa de dados meteorol√≥gicos que fornece:
- Condi√ß√µes clim√°ticas atuais e hist√≥ricas
- Previs√µes meteorol√≥gicas de 5-16 dias
- Dados de temperatura, precipita√ß√£o, humidade, vento
- √çndices UV e qualidade do ar

**‚öôÔ∏è M√©todo de Acesso:**
```python
# Exemplo de implementa√ß√£o
import requests
import asyncio

class WeatherDataCollector:
    def __init__(self, api_key):
        self.api_key = api_key
        self.base_url = "https://api.openweathermap.org/data/2.5"
    
    async def get_weather_data(self, city, country="AO"):
        url = f"{self.base_url}/weather"
        params = {
            'q': f"{city},{country}",
            'appid': self.api_key,
            'units': 'metric'
        }
        # Implementa√ß√£o da coleta...
```

**üìÑ Formato dos Dados:** JSON via REST API

**üóÑÔ∏è Plano de Armazenamento:**
```sql
CREATE TABLE weather_data (
    id SERIAL PRIMARY KEY,
    cidade VARCHAR(100),
    latitude DECIMAL(10,8),
    longitude DECIMAL(11,8),
    data_medicao TIMESTAMP,
    temperatura DECIMAL(5,2),
    temperatura_min DECIMAL(5,2),
    temperatura_max DECIMAL(5,2),
    precipitacao DECIMAL(5,2),
    humidade INTEGER,
    velocidade_vento DECIMAL(5,2),
    condicao_clima VARCHAR(50),
    created_at TIMESTAMP DEFAULT NOW()
);
```

**üéØ Uso no Modelo:**
- **Feature engineering:** Vari√°vel clim√°tica nos modelos de recomenda√ß√£o
- **An√°lise sazonal:** Correla√ß√£o clima vs. fluxo tur√≠stico
- **Recomenda√ß√µes din√¢micas:** Sugest√£o de atividades baseadas no clima
- **Alertas:** Notifica√ß√µes sobre condi√ß√µes clim√°ticas adversas

---

### üó∫Ô∏è 3. OpenStreetMap - Dados Geogr√°ficos

**üîó Link:** [https://overpass-turbo.eu/](https://overpass-turbo.eu/)

**üìã Descri√ß√£o:**
Base de dados geogr√°fica colaborativa que fornece:
- Localiza√ß√£o de pontos tur√≠sticos
- Hot√©is, restaurantes e servi√ßos
- Rede rodovi√°ria e transportes
- Fronteiras administrativas
- Infraestruturas tur√≠sticas

**‚öôÔ∏è M√©todo de Acesso:**
```python
# Exemplo usando Overpass API
import overpy
import osmnx as ox

class OSMDataCollector:
    def __init__(self):
        self.api = overpy.Overpass()
    
    def get_tourism_pois(self, bbox):
        query = f"""
        [out:json][timeout:25];
        (
          node["tourism"]{bbox};
          way["tourism"]{bbox};
          relation["tourism"]{bbox};
        );
        out geom;
        """
        return self.api.query(query)
```

**üìÑ Formato dos Dados:** GeoJSON, XML

**üóÑÔ∏è Plano de Armazenamento:**
```sql
-- Usando PostGIS para dados geoespaciais
CREATE EXTENSION postgis;

CREATE TABLE pontos_turisticos (
    id SERIAL PRIMARY KEY,
    osm_id BIGINT UNIQUE,
    nome VARCHAR(255),
    tipo_turismo VARCHAR(100),
    categoria VARCHAR(50),
    geometria GEOMETRY(POINT, 4326),
    endereco JSONB,
    tags JSONB,
    created_at TIMESTAMP DEFAULT NOW()
);

CREATE INDEX idx_pontos_turisticos_geom 
ON pontos_turisticos USING GIST (geometria);
```

**üéØ Uso no Modelo:**
- **Visualiza√ß√£o:** Renderiza√ß√£o de mapas interativos
- **An√°lise espacial:** Densidade de pontos tur√≠sticos por regi√£o
- **Recomenda√ß√µes geogr√°ficas:** Sugest√£o de locais pr√≥ximos
- **Roteamento:** C√°lculo de dist√¢ncias e rotas tur√≠sticas

---

### ‚úàÔ∏è 4. FlightRadar24 - Dados de Tr√°fego A√©reo

**üîó Link:** [https://www.flightradar24.com](https://www.flightradar24.com)

**üìã Descri√ß√£o:**
Plataforma de monitoriza√ß√£o de tr√°fego a√©reo que fornece:
- Voos em tempo real
- Estat√≠sticas de aeroportos angolanos
- Rotas internacionais e dom√©sticas
- Dados hist√≥ricos de conectividade

**‚öôÔ∏è M√©todo de Acesso:**
```python
# Scraping controlado com rate limiting
import time
from selenium import webdriver
from selenium.webdriver.common.by import By

class FlightDataCollector:
    def __init__(self):
        self.driver = webdriver.Chrome()
        self.rate_limit = 2  # segundos entre requests
    
    def get_airport_stats(self, airport_code):
        url = f"https://www.flightradar24.com/data/airports/{airport_code}"
        # Implementa√ß√£o com respeito aos termos de uso...
        time.sleep(self.rate_limit)
```

**üìÑ Formato dos Dados:** HTML (scraping), JSON (se API dispon√≠vel)

**üóÑÔ∏è Plano de Armazenamento:**
```sql
CREATE TABLE voos_dados (
    id SERIAL PRIMARY KEY,
    codigo_voo VARCHAR(10),
    aeroporto_origem VARCHAR(4),
    aeroporto_destino VARCHAR(4),
    data_voo DATE,
    hora_partida TIME,
    hora_chegada TIME,
    companhia_aerea VARCHAR(100),
    tipo_aeronave VARCHAR(50),
    status_voo VARCHAR(20),
    created_at TIMESTAMP DEFAULT NOW()
);
```

**üéØ Uso no Modelo:**
- **Previs√£o de chegadas:** Antecipa√ß√£o de fluxo de turistas internacionais
- **An√°lise de conectividade:** Identifica√ß√£o de mercados-fonte principais
- **Sazonalidade:** Padr√µes de voos vs. √©pocas tur√≠sticas
- **Capacidade aeroportu√°ria:** An√°lise de infraestrutura de transporte

---

### üè® 5. Google Places API - Avalia√ß√µes e POIs

**üîó Link:** [https://developers.google.com/maps/documentation/places/web-service](https://developers.google.com/maps/documentation/places/web-service)

**üìã Descri√ß√£o:**
API oficial do Google que fornece:
- Informa√ß√µes detalhadas de estabelecimentos
- Avalia√ß√µes e classifica√ß√µes de utilizadores
- Fotos e hor√°rios de funcionamento
- Dados de popularidade e tend√™ncias

**‚öôÔ∏è M√©todo de Acesso:**
```python
import googlemaps

class GooglePlacesCollector:
    def __init__(self, api_key):
        self.gmaps = googlemaps.Client(key=api_key)
    
    def search_tourism_places(self, location, radius=50000):
        places = self.gmaps.places_nearby(
            location=location,
            radius=radius,
            type='tourist_attraction'
        )
        return places
```

**üìÑ Formato dos Dados:** JSON via REST API

**üóÑÔ∏è Plano de Armazenamento:**
```sql
CREATE TABLE google_places (
    id SERIAL PRIMARY KEY,
    place_id VARCHAR(255) UNIQUE,
    nome VARCHAR(255),
    categoria VARCHAR(100),
    rating DECIMAL(2,1),
    total_avaliacoes INTEGER,
    preco_nivel INTEGER,
    latitude DECIMAL(10,8),
    longitude DECIMAL(11,8),
    endereco TEXT,
    telefone VARCHAR(20),
    website VARCHAR(255),
    horarios JSONB,
    fotos JSONB,
    updated_at TIMESTAMP DEFAULT NOW()
);
```

**üéØ Uso no Modelo:**
- **Sistema de recomenda√ß√£o:** Ranking baseado em avalia√ß√µes
- **An√°lise de sentimento:** Processamento de reviews
- **Popularidade:** Identifica√ß√£o de trending destinations
- **Qualidade de servi√ßo:** M√©tricas de satisfa√ß√£o do cliente

---

## üèóÔ∏è Arquitetura de Armazenamento

### üìÅ Estrutura de Diret√≥rios
```
/data
‚îú‚îÄ‚îÄ raw/                    # Dados brutos originais
‚îÇ   ‚îú‚îÄ‚îÄ ine/               # Relat√≥rios INE (PDF, XLSX)
‚îÇ   ‚îú‚îÄ‚îÄ weather/           # Dados clim√°ticos (JSON)
‚îÇ   ‚îú‚îÄ‚îÄ osm/               # Exports OpenStreetMap (XML, GeoJSON)
‚îÇ   ‚îú‚îÄ‚îÄ flights/           # Dados de voos (CSV, JSON)
‚îÇ   ‚îî‚îÄ‚îÄ google_places/     # Dados Google Places (JSON)
‚îú‚îÄ‚îÄ processed/             # Dados limpos e normalizados
‚îÇ   ‚îú‚îÄ‚îÄ tourism_stats/     # Estat√≠sticas processadas
‚îÇ   ‚îú‚îÄ‚îÄ weather_clean/     # Dados clim√°ticos limpos
‚îÇ   ‚îú‚îÄ‚îÄ geo_processed/     # Dados geogr√°ficos processados
‚îÇ   ‚îî‚îÄ‚îÄ reviews_processed/ # Avalia√ß√µes processadas
‚îî‚îÄ‚îÄ model/                 # Datasets prontos para ML
    ‚îú‚îÄ‚îÄ features/          # Features engineered
    ‚îú‚îÄ‚îÄ training/          # Dados de treino
    ‚îî‚îÄ‚îÄ validation/        # Dados de valida√ß√£o
```

### üóÉÔ∏è Camadas de Dados

#### **Camada Raw (Bruta)**
- **Prop√≥sito:** Armazenamento de dados originais sem modifica√ß√£o
- **Tecnologia:** Google Cloud Storage / AWS S3
- **Reten√ß√£o:** Permanente (backup e auditoria)

#### **Camada Processed (Processada)**
- **Prop√≥sito:** Dados limpos, normalizados e estruturados
- **Tecnologia:** PostgreSQL + PostGIS
- **Caracter√≠sticas:**
  - Esquemas normalizados
  - √çndices otimizados
  - Constraints de integridade
  - Triggers de auditoria

#### **Camada Model (Modelo)**
- **Prop√≥sito:** Datasets otimizados para Machine Learning
- **Tecnologia:** PostgreSQL + Data Warehouse
- **Caracter√≠sticas:**
  - Features engineered
  - Dados balanceados
  - Formato otimizado para treino

---

## ‚öôÔ∏è Stack Tecnol√≥gico

### üêç Linguagens e Frameworks
| Tecnologia | Fun√ß√£o | Justificativa |
|------------|--------|---------------|
| **Python 3.9+** | Linguagem principal | Ecossistema ML robusto |
| **Pandas** | Manipula√ß√£o de dados | Performance e facilidade |
| **NumPy** | Computa√ß√£o num√©rica | Base para an√°lise cient√≠fica |
| **Scikit-learn** | Machine Learning | Algoritmos testados e documentados |
| **GeoPandas** | Dados geoespaciais | Integra√ß√£o GIS com Pandas |

### üï∑Ô∏è Coleta de Dados
| Ferramenta | Uso | Configura√ß√£o |
|------------|-----|--------------|
| **BeautifulSoup** | Web scraping HTML | `pip install beautifulsoup4` |
| **Selenium** | Scraping din√¢mico | `pip install selenium` |
| **Requests** | APIs REST | `pip install requests` |
| **aiohttp** | Requests ass√≠ncronos | `pip install aiohttp` |
| **Scrapy** | Scraping em escala | `pip install scrapy` |

### üóÑÔ∏è Armazenamento e Processamento
| Componente | Tecnologia | Configura√ß√£o |
|------------|------------|--------------|
| **Banco Principal** | PostgreSQL 14+ | Com extens√£o PostGIS |
| **Cache** | Redis | Para dados tempor√°rios |
| **Object Storage** | Google Cloud Storage | Dados brutos e backups |
| **ETL** | Apache Airflow | Orquestra√ß√£o de pipelines |
| **Monitoriza√ß√£o** | Prometheus + Grafana | M√©tricas e alertas |

### üìä An√°lise e Desenvolvimento
| Ferramenta | Prop√≥sito |
|------------|-----------|
| **Jupyter Notebooks** | An√°lise explorat√≥ria e prototipagem |
| **DBeaver** | Administra√ß√£o de base de dados |
| **QGIS** | An√°lise e visualiza√ß√£o geoespacial |
| **Git + GitHub** | Controlo de vers√£o e colabora√ß√£o |

---

## üîÑ Pipeline de Dados

### 1Ô∏è‚É£ **Extra√ß√£o (Extract)**
```python
# Exemplo de pipeline de extra√ß√£o
class DataExtractor:
    def __init__(self):
        self.collectors = {
            'ine': INEDataCollector(),
            'weather': WeatherDataCollector(),
            'osm': OSMDataCollector(),
            'flights': FlightDataCollector(),
            'places': GooglePlacesCollector()
        }
    
    async def extract_all(self):
        tasks = []
        for source, collector in self.collectors.items():
            task = asyncio.create_task(collector.collect())
            tasks.append(task)
        
        results = await asyncio.gather(*tasks)
        return dict(zip(self.collectors.keys(), results))
```

### 2Ô∏è‚É£ **Transforma√ß√£o (Transform)**
```python
class DataTransformer:
    def clean_tourism_data(self, raw_data):
        # Limpeza e normaliza√ß√£o
        df = pd.DataFrame(raw_data)
        df = df.dropna(subset=['visitantes', 'provincia'])
        df['data'] = pd.to_datetime(df['data'])
        df['visitantes'] = pd.to_numeric(df['visitantes'], errors='coerce')
        return df
    
    def engineer_features(self, df):
        # Feature engineering
        df['mes'] = df['data'].dt.month
        df['trimestre'] = df['data'].dt.quarter
        df['ano'] = df['data'].dt.year
        df['sazonalidade'] = df['mes'].map(self.get_season_map())
        return df
```

### 3Ô∏è‚É£ **Carregamento (Load)**
```python
class DataLoader:
    def __init__(self, db_connection):
        self.db = db_connection
    
    def load_to_postgres(self, df, table_name):
        df.to_sql(
            table_name, 
            self.db, 
            if_exists='append',
            index=False,
            method='multi'
        )
```

### üïê **Agendamento com Airflow**
```python
from airflow import DAG
from airflow.operators.python_operator import PythonOperator
from datetime import datetime, timedelta

default_args = {
    'owner': 'wenda-data-team',
    'depends_on_past': False,
    'start_date': datetime(2024, 1, 1),
    'email_on_failure': True,
    'email_on_retry': False,
    'retries': 2,
    'retry_delay': timedelta(minutes=5)
}

dag = DAG(
    'wenda_data_pipeline',
    default_args=default_args,
    description='Pipeline de coleta de dados Wenda',
    schedule_interval='@daily',
    catchup=False
)

extract_task = PythonOperator(
    task_id='extract_data',
    python_callable=extract_all_sources,
    dag=dag
)

transform_task = PythonOperator(
    task_id='transform_data',
    python_callable=transform_all_data,
    dag=dag
)

load_task = PythonOperator(
    task_id='load_data',
    python_callable=load_to_warehouse,
    dag=dag
)

extract_task >> transform_task >> load_task
```

---

## üìà Monitoriza√ß√£o e Qualidade dos Dados

### üéØ **M√©tricas de Qualidade**
- **Completude:** % de campos preenchidos
- **Consist√™ncia:** Valida√ß√£o de formatos e tipos
- **Precis√£o:** Verifica√ß√£o de valores v√°lidos
- **Atualidade:** Frequ√™ncia de atualiza√ß√£o
- **Integridade:** Rela√ß√µes entre tabelas

### üö® **Sistema de Alertas**
```python
class DataQualityMonitor:
    def __init__(self):
        self.thresholds = {
            'completeness': 0.95,
            'freshness_hours': 24,
            'anomaly_threshold': 2.0
        }
    
    def check_data_quality(self, table_name):
        checks = [
            self.check_completeness(table_name),
            self.check_freshness(table_name),
            self.check_anomalies(table_name)
        ]
        
        failed_checks = [c for c in checks if not c['passed']]
        if failed_checks:
            self.send_alert(table_name, failed_checks)
```

### üìä **Dashboard de Monitoriza√ß√£o**
- **Grafana:** Visualiza√ß√£o de m√©tricas em tempo real
- **Prometheus:** Coleta de m√©tricas do sistema
- **Alertmanager:** Gest√£o de alertas e notifica√ß√µes

---

## üîí Considera√ß√µes de Seguran√ßa e Compliance

### üõ°Ô∏è **Seguran√ßa dos Dados**
- **Encripta√ß√£o:** Dados sens√≠veis encriptados em repouso e em tr√¢nsito
- **Acesso:** Controlo baseado em roles (RBAC)
- **Auditoria:** Log de todas as opera√ß√µes de dados
- **Backup:** Backups autom√°ticos com reten√ß√£o de 90 dias

### ‚öñÔ∏è **Compliance Legal**
- **GDPR:** Conformidade com regulamenta√ß√£o europeia
- **Lei de Prote√ß√£o de Dados de Angola:** Cumprimento da legisla√ß√£o local
- **Termos de Uso:** Respeito aos ToS de todas as APIs utilizadas
- **Rate Limiting:** Implementa√ß√£o de limites para evitar sobrecarga

### üîë **Gest√£o de Credenciais**
```python
# Exemplo de gest√£o segura de API keys
import os
from cryptography.fernet import Fernet

class SecureConfig:
    def __init__(self):
        self.cipher = Fernet(os.environ['ENCRYPTION_KEY'])
    
    def get_api_key(self, service):
        encrypted_key = os.environ[f'{service.upper()}_API_KEY_ENCRYPTED']
        return self.cipher.decrypt(encrypted_key.encode()).decode()
```

---

## üöÄ Roadmap de Implementa√ß√£o

### **Fase 1: Funda√ß√£o (Semanas 1-2)**
- [ ] Configura√ß√£o da infraestrutura base (PostgreSQL + PostGIS)
- [ ] Implementa√ß√£o dos coletores b√°sicos (INE + Weather)
- [ ] Pipeline ETL inicial
- [ ] Testes unit√°rios e integra√ß√£o

### **Fase 2: Expans√£o (Semanas 3-4)**
- [ ] Integra√ß√£o OpenStreetMap e Google Places
- [ ] Sistema de monitoriza√ß√£o com Grafana
- [ ] Otimiza√ß√£o de performance
- [ ] Documenta√ß√£o t√©cnica completa

### **Fase 3: Produ√ß√£o (Semanas 5-6)**
- [ ] Deploy em ambiente de produ√ß√£o
- [ ] Configura√ß√£o de alertas e backups
- [ ] Testes de carga e stress
- [ ] Treinamento da equipa

### **Fase 4: Otimiza√ß√£o (Ongoing)**
- [ ] Machine Learning para detec√ß√£o de anomalias
- [ ] Auto-scaling baseado em demanda
- [ ] Integra√ß√£o de novas fontes de dados
- [ ] An√°lise preditiva de qualidade

---

## üìù Conclus√£o

Esta estrat√©gia de dados estabelece uma base s√≥lida e escal√°vel para o projeto Wenda, garantindo que o modelo de Machine Learning tenha acesso a dados de alta qualidade, atualizados e diversificados. A arquitetura proposta permite:

- **Escalabilidade:** F√°cil adi√ß√£o de novas fontes de dados
- **Confiabilidade:** Monitoriza√ß√£o cont√≠nua e sistema de alertas
- **Performance:** Otimiza√ß√£o para consultas anal√≠ticas
- **Manutenibilidade:** C√≥digo limpo e bem documentado
- **Seguran√ßa:** Prote√ß√£o de dados sens√≠veis e compliance legal

O sucesso desta implementa√ß√£o ser√° medido pela qualidade das recomenda√ß√µes da Wenda e pela satisfa√ß√£o dos utilizadores finais, criando um ciclo virtuoso de melhoria cont√≠nua baseado em dados reais e feedback do mercado.

---

**Documento preparado por:** Equipa de Dados - Projeto Wenda  
**Data:** Outubro 2024  
**Vers√£o:** 1.0  
**Pr√≥xima revis√£o:** Novembro 2024
